# Credit Card Fraud Detection

This project uses machine learning techniques to detect fraudulent credit card transactions based on a dataset of transactions. The dataset contains a mix of legitimate and fraudulent transactions, with a target variable indicating whether a transaction is fraudulent or not.

## Project Overview

In this project, we apply various machine learning algorithms to predict whether a credit card transaction is fraudulent or legitimate. The primary goal is to evaluate the performance of different models using a balanced dataset generated by applying **SMOTE (Synthetic Minority Over-sampling Technique)** to address class imbalance.

## Dataset

The dataset used in this project is the **Creditcard_data.csv** file, which contains features related to credit card transactions. The key features of the dataset are:

- **V1, V2, ..., V28**: 28 anonymized features describing transaction details.
- **Amount**: The transaction amount.
- **Class**: The target variable, where `1` indicates a fraudulent transaction and `0` indicates a legitimate transaction.

## Project Steps

1. **Data Loading**: The dataset is loaded into a Pandas DataFrame for processing.
2. **Data Preprocessing**:
   - Class imbalance is addressed using **SMOTE** to generate synthetic data for the minority class (fraudulent transactions).
3. **Data Sampling**:
   - Five different samples are created from the balanced dataset using various sampling methods:
     - Random sampling (two samples with different random seeds)
     - Stratified sampling to maintain the class distribution
     - First and last 200 rows of the dataset
4. **Modeling**:
   - Five machine learning models are used to predict fraudulent transactions:
     - Random Forest
     - Naive Bayes
     - XGBoost
     - K-Nearest Neighbors (KNN)
     - Logistic Regression
5. **Evaluation**: 
   - Each model is trained on the training set and evaluated on the test set, with accuracy being used as the evaluation metric.
6. **Saving the Samples**:
   - The generated samples are saved as CSV files for future use.


## Results 
# Model Performance Summary

| Model               | Sample 1 | Sample 2 | Sample 3 | **Sample 4 (Best)** | Sample 5 |
|---------------------|----------|----------|----------|---------------------|----------|
| **Random Forest**    | 0.97     | 0.95     | 0.98     | **0.98**            | Not enough class representation |
| **Logistic Regression** | 0.87     | 0.83     | 0.90     | **0.98**            | Not enough class representation |
| **SVM**              | 0.68     | 0.48     | 0.66     | **0.98**            | Not enough class representation |
| **KNN**              | 0.77     | 0.73     | 0.75     | **0.98**            | Not enough class representation |
| **Decision Tree**    | 0.90     | 0.87     | 0.94     | **0.98**            | Not enough class representation |

## Notes:
- **Sample 4 (Oversampling)** shows the highest accuracy for all models.
- **Sample 5** had insufficient class representation for training and testing, leading to skipping.


